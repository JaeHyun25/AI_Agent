# ë‹¤ í†µí•©í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì½”ë“œ

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from langchain_core.language_models.llms import LLM
from typing import Any, List, Mapping, Optional, Dict
import warnings
import pymysql
import pandas as pd
import matplotlib.pyplot as plt
import os
import io
import sys
from contextlib import redirect_stdout
import re

# --- 0. í™˜ê²½ ì„¤ì • ë° ê²½ê³  ë¬´ì‹œ ---
warnings.filterwarnings("ignore")
plt.rcParams['font.family'] = 'NanumGothic' # <-- ì˜ˆì‹œ: ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ì„¤ì • (ì‹œìŠ¤í…œì— ì„¤ì¹˜ í•„ìš”)
plt.rcParams['axes.unicode_minus'] = False # <-- ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€

# --- 1. CustomGemmaLLM í´ë˜ìŠ¤ ì •ì˜ (ì´ì „ ì½”ë“œ ì¬ì‚¬ìš©) ---
class CustomGemmaLLM(LLM):
    tokenizer: Any = None
    model: Any = None
    device: str = "cuda:0"
    model_path: str = None

    def __init__(self, model_path: str):
        super().__init__()
        self.model_path = model_path
        print("1. í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...")
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        print("2. ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_path,
            torch_dtype=torch.bfloat16
        ).to(self.device).eval()
        print(f"   - ëª¨ë¸ì„ {self.model.device} ì¥ì¹˜ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    @property
    def _llm_type(self) -> str:
        return "custom_gemma"

    def _call(self, prompt: str, stop: Optional[List[str]] = None, **kwargs: Any) -> str:
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=1024, # ì½”ë“œ ìƒì„±ì„ ìœ„í•´ í† í° ìˆ˜ ëŠ˜ë¦¼
                do_sample=True,
                temperature=0.2, # ì½”ë“œ ìƒì„± ì‹œì—ëŠ” ì•½ê°„ ë‚®ì¶¤
                top_p=0.95,
                pad_token_id=self.tokenizer.pad_token_id
            )
        input_length = inputs['input_ids'].shape[1]
        output_text = self.tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)
        return output_text

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        return {"model_path": self.model_path}

# --- 2. LLM ë° DB ì •ë³´ ì„¤ì • ---
model_path = "/home/ubuntu/models/gemma-3-12b-it/models--google--gemma-3-12b-it/snapshots/96b6f1eccf38110c56df3a15bffe176da04bfd80"
llm = CustomGemmaLLM(model_path=model_path)

db_host = "127.0.0.1"
db_user = "root"
db_password = "rootpass"
db_name = "sakila"

# --- 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ ---
planner_prompt_template = """### Instruction:
You are an intelligent AI assistant. Your job is to understand the user's request and determine which capability is needed to fulfill it.
You have the following capabilities:
1.  **db_querier**: Sakila ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´(ë°°ìš°, ì˜í™”, ê³ ê° ë“±)ë¥¼ ë¬¼ì–´ë³¼ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
2.  **excel_analyzer**: Excel(.xlsx) ë˜ëŠ” CSV íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ì½ê±°ë‚˜ ë¶„ì„/ì²˜ë¦¬í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
3.  **visualizer**: ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë˜í”„ë‚˜ ì°¨íŠ¸(ë§‰ëŒ€, ì„  ë“±)ë¥¼ ê·¸ë ¤ë‹¬ë¼ê³  ìš”ì²­í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
4.  **file_reader**: ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ë‹¬ë¼ê³  ìš”ì²­í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
5.  **file_writer**: ì •ë³´ë¥¼ ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì €ì¥í•´ë‹¬ë¼ê³  ìš”ì²­í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
6.  **general_qa**: ìœ„ì˜ ì–´ëŠ ê²ƒì—ë„ í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µí•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
Based on the user's question below, output *only* the name of the single most relevant capability from the list above.

Question: {user_question}
### Capability:"""

sql_gen_prompt_template = """### Instruction:
You are a MySQL expert. You know the Sakila database schema.
Key tables:
- actor(actor_id, first_name, last_name)
- film(film_id, title, description, release_year)
- film_actor(actor_id, film_id)
Based on the user's question, generate a single, executable MySQL query.
Make sure to JOIN tables correctly if needed.
Use actor.first_name and actor.last_name for filtering.
Only SELECT the requested columns. Add LIMIT if asked.

Question: {user_question}
### MySQL Query:"""

python_gen_prompt_template = """### Instruction:
You are a Python expert specializing in pandas, matplotlib, and file operations.
Based on the user's request, generate only the Python code required to perform the task.
Assume pandas is imported as pd and matplotlib.pyplot as plt.
Use standard Python file I/O (with utf-8 encoding).
Ensure any plots are saved to a file (default: 'output.png').
Ensure the code is a single, executable block.

Request: {user_question}
### Python Code:"""

# --- 4. í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---
# LLMì˜ ì „ì²´ ì¶œë ¥ ë¬¸ìì—´ì—ì„œ ì‹¤ì œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_code(llm_output: str) -> str:
    """LLM ì¶œë ¥ì—ì„œ ì½”ë“œ ë¸”ëŸ­(```) ë˜ëŠ” íŠ¹ì • í‚¤ì›Œë“œ ì´í›„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    match = re.search(r"```(?:python|sql)?\s*(.*?)```", llm_output, re.DOTALL)
    if match:
        return match.group(1).strip()    # ì‹¤ì œ ì½”ë“œ ë‚´ìš© ë¶€ë¶„ ê°€ì ¸ì™€ì„œ ê³µë°± ì œê±° í•˜ê³  ë°˜í™˜
    
    keywords = ["### Python Code:", "### MySQL Query:"]    # ìš°ë¦¬ê°€ í”„ë¡¬í”„íŠ¸ì—ì„œ ì‚¬ìš©í•œ í‚¤ì›Œë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì½”ë“œë¥¼ ì¶”
    for keyword in keywords:
        if keyword in llm_output:
            return llm_output.split(keyword)[1].strip()    # í‚¤ì›Œë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ìì—´ì„ ë‚˜ëˆ„ê³ , í‚¤ì›Œë“œ ì´í›„ì˜ ë¶€ë¶„ì„ ê°€ì ¸ì™€ ì•ë’¤ ê³µë°± ì œê±°í•˜ê³  ë°˜í™˜
            
    # ìœ„ íŒ¨í„´ì´ ì—†ìœ¼ë©´, ê·¸ëƒ¥ ì „ì²´ ì¶œë ¥ì„ ë°˜í™˜ (LLMì´ ì½”ë“œë§Œ ì¶œë ¥í–ˆë‹¤ê³  ê°€ì •)
    return llm_output.strip()
    
def execute_sql(sql_query: str) -> str:
    """SQL ì¿¼ë¦¬ë¥¼ ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        conn = pymysql.connect(
            host=db_host, user=db_user, password=db_password, database=db_name,
            charset="utf8mb4", cursorclass=pymysql.cursors.DictCursor             # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°›ê¸° ìœ„í•œ ì»¤ì„œ ì„¤ì •, ë¬¸ì ì¸ì½”ë”©ì„ utf8mb4ë¡œ ì„¤ì •í•˜ì—¬ í•œê¸€ ë“± ë‹¤êµ­ì–´ ì§€ì›
        )
        with conn.cursor() as cursor:
            cursor.execute(sql_query.replace(';', ''))    # pymysqlì€ ; ì—†ì–´ë„ ì˜ ì‹¤í–‰ë˜ì„œ ì„¸ë¯¸ì½œë¡  ì œê±°í•˜ê³  sql ì¿¼ë¦¬ ì‹¤í–‰
            results = cursor.fetchall()    # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì‹¤í–‰ ê²°ê³¼ ê°€ì ¸ì˜´
        conn.close()
        return str(results) if results else "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âŒ SQL ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}"

def execute_python(python_code: str) -> str:
    """Python ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³  í‘œì¤€ ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    f = io.StringIO()    # ì¶œë ¥ì„ io.StringIO ê°ì²´ë¡œ ë³´ë‚´ê¸°ìœ„í•´ ìƒ
    try:
        with redirect_stdout(f):
            exec(python_code, {"pd": pd, "plt": plt, "os": os})
        output = f.getvalue()
        # íŒŒì¼ ìƒì„± ì—¬ë¶€ í™•ì¸ (visualizer ê²½ìš°)
        if 'plt.savefig' in python_code:
             # íŒŒì¼ ì´ë¦„ ì¶”ì¶œ ì‹œë„ (ê°„ë‹¨í•œ ë°©ì‹)
             match = re.search(r"plt\.savefig\(['\"](.*?)['\"]\)", python_code)
             if match and os.path.exists(match.group(1)):
                 output += f"\nâœ… '{match.group(1)}' íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
             else:
                 output += "\nâš ï¸ ê·¸ë˜í”„ íŒŒì¼ ìƒì„± ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        return output if output else "ì½”ë“œê°€ ì‹¤í–‰ë˜ì—ˆìœ¼ë‚˜, ì¶œë ¥ì€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"âŒ Python ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\n{f.getvalue()}"

# ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„, ì–´ë–¤ ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ì•¼ í•  ì§€ ê²°ì •í•˜ëŠ” 'í”Œë˜ë„ˆ' ì—­í• ì„ í•˜ëŠ” í•¨ìˆ˜
def get_capability(user_question: str, llm: LLM) -> str:
    """í”Œë˜ë„ˆ LLMì„ í˜¸ì¶œí•˜ì—¬ ê¸°ëŠ¥ì„ ê²°ì •í•©ë‹ˆë‹¤."""
    prompt = planner_prompt_template.format(user_question=user_question)    # ë¯¸ë¦¬ ì •ì˜ëœ planner_prompt_templateì— ì‚¬ìš©ì ì§ˆë¬¸ì„ ë„£ì–´ ì „ì²´ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±.
    response = llm.invoke(prompt)    # ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ë¥¼ llm(CustomGemmaLLM ì¸ìŠ¤í„´ìŠ¤)ì— ì „ë‹¬í•˜ì—¬ ì‘ë‹µ(ê¸°ëŠ¥ ì´ë¦„)ì„ ë°›ëŠ”ë‹¤.
    return extract_code(response) # ì½”ë“œ ì¶”ì¶œ í•¨ìˆ˜ ì¬í™œìš©

# ê²°ì •ëœ ê¸°ëŠ¥ê³¼ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë°›ì•„, í•´ë‹¹ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ì½”ë“œ(SQL or Python)ë¥¼ ìƒì„±í•˜ëŠ” í•¨
def generate_code(capability: str, user_question: str, llm: LLM) -> Optional[str]:
    """ê¸°ëŠ¥ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if capability == 'db_querier':
        prompt = sql_gen_prompt_template.format(user_question=user_question)
    elif capability in ['excel_analyzer', 'visualizer', 'file_reader', 'file_writer']:
        prompt = python_gen_prompt_template.format(user_question=user_question)
    else:
        return None
        
    generated_output = llm.invoke(prompt)    # ì„ íƒëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì‚¬ìš©ì ì§ˆë¬¸ì„ ë„£ì–´ ì „ì²´ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±í•˜ê³ , llmì— ì „ë‹¬í•˜ì—¬ ì½”ë“œ ìƒì„± ìš”ì²­
    return extract_code(generated_output)    # LLMì´ ìƒì„±í•œ ì „ì²´ ì¶œë ¥ì—ì„œ ì‹¤ì œ ì½”ë“œ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜

# --- 5. ë©”ì¸ AI ì—ì´ì „íŠ¸ í•¨ìˆ˜ ---
def run_ai_agent(user_question: str):
    print(f"\n========================================")
    print(f"ğŸ¤– ì‚¬ìš©ì ì§ˆë¬¸: {user_question}")
    print(f"========================================")

    # 1. ê¸°ëŠ¥ ê²°ì • (í”Œë˜ë„ˆ)
    capability = get_capability(user_question, llm)
    print(f"ğŸ§  ì—ì´ì „íŠ¸ íŒë‹¨: '{capability}' ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # 2. ì½”ë“œ ìƒì„± (ì½”ë“œ ìƒì„±ê¸°)
    if capability in ['db_querier', 'excel_analyzer', 'visualizer', 'file_reader', 'file_writer']:
        code_to_run = generate_code(capability, user_question, llm)
        if not code_to_run:
            print("âŒ ì½”ë“œë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        print(f"\nğŸ’» ìƒì„±ëœ ì½”ë“œ:\n---\n{code_to_run}\n---")

        # 3. ì½”ë“œ ì‹¤í–‰ (ì‹¤í–‰ê¸°)
        if capability == 'db_querier':
            result = execute_sql(code_to_run)
        else:
            result = execute_python(code_to_run)
            
        print(f"\nğŸ“Š ì‹¤í–‰ ê²°ê³¼:\n---\n{result}\n---")

    elif capability == 'general_qa':
        print("\nğŸ—£ï¸ ì¼ë°˜ ì§ˆë¬¸ì…ë‹ˆë‹¤. LLMì—ê²Œ ì§ì ‘ ë¬¼ì–´ë´…ë‹ˆë‹¤...")
        # ê°„ë‹¨í•œ QAë¥¼ ìœ„í•´ LLM ì§ì ‘ í˜¸ì¶œ (í”„ë¡¬í”„íŠ¸ ê°œì„  í•„ìš”)
        qa_prompt = f"Please answer the following question: {user_question}"
        answer = llm.invoke(qa_prompt)
        print(f"\nğŸ“Š LLM ë‹µë³€:\n---\n{answer}\n---")
    else:
        print("ğŸ¤·â€â™‚ï¸ ì´ ì§ˆë¬¸ì€ ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì•¼ í• ì§€ ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.")

    print(f"========================================")
